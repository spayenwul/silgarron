# services/llm_service.py
import os
from typing import List
import google.generativeai as genai
from dotenv import load_dotenv
from typing import List, Optional
import json
from utils.logger import log_llm_interaction 
from logic.constants import *

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è (–≤–∫–ª—é—á–∞—è –Ω–∞—à API –∫–ª—é—á) –∏–∑ —Ñ–∞–π–ª–∞ .env
load_dotenv()

API_KEY = os.getenv("GEMINI_API_KEY")
MODEL_NAME = os.getenv("GEMINI_MODEL", "gemini-2.5-pro") 


try:
    if not API_KEY:
        raise ValueError("–ö–ª—é—á API Gemini –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª .env –∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é GEMINI_API_KEY.")
    
    genai.configure(api_key=API_KEY)
    print(f"–°–µ—Ä–≤–∏—Å Gemini —É—Å–ø–µ—à–Ω–æ —Å–∫–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä–æ–≤–∞–Ω. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–æ–¥–µ–ª—å: {MODEL_NAME}")

except Exception as e:
    print(f"–û—à–∏–±–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ Gemini: {e}")


def generate_location_description(tags: List[str], context: Optional[List[str]] = None) -> str:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ–ø–∏—Å–∞–Ω–∏–µ –ª–æ–∫–∞—Ü–∏–∏, –∏—Å–ø–æ–ª—å–∑—É—è –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –ø–∞–º—è—Ç–∏.
    """
    model = genai.GenerativeModel(MODEL_NAME)
    tags_str = ", ".join(tags)

    # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞–µ–º –ø—Ä–æ–º–ø—Ç
    prompt_parts = [
        "–¢—ã ‚Äî –º–∞—Å—Ç–µ—Ä –ø–æ–¥–∑–µ–º–µ–ª–∏–π –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤–æ–π —Ä–æ–ª–µ–≤–æ–π –∏–≥—Ä—ã –≤ –∂–∞–Ω—Ä–µ —Ç—ë–º–Ω–æ–≥–æ —Ñ—ç–Ω—Ç–µ–∑–∏.",
        "–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–æ—Ä–æ—Ç–∫–æ–µ, –∞—Ç–º–æ—Å—Ñ–µ—Ä–Ω–æ–µ –∏ —è—Ä–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –ª–æ–∫–∞—Ü–∏–∏ (3-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è).",
        "–ù–µ –∏—Å–ø–æ–ª—å–∑—É–π –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è –∏–ª–∏ –ª–∏—à–Ω–∏–µ —Ñ—Ä–∞–∑—ã, —Ç–æ–ª—å–∫–æ —Å–∞–º —Ç–µ–∫—Å—Ç –æ–ø–∏—Å–∞–Ω–∏—è.",
        f"–ö–ª—é—á–µ–≤—ã–µ —Ç–µ–≥–∏ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: [{tags_str}]"
    ]
    # –ï—Å–ª–∏ –Ω–∞–º –ø–µ—Ä–µ–¥–∞–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç, –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ –≤ –ø—Ä–æ–º–ø—Ç
    if context:
        context_str = "\n".join(f"- {item}" for item in context)
        prompt_parts.append(
            "\n–£—á—Ç–∏ —Å–ª–µ–¥—É—é—â—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ –º–∏—Ä–∞ (—ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–ª—É—Ö, —Ñ–∞–∫—Ç –∏–ª–∏ –ø—Ä–æ—à–ª–æ–µ —Å–æ–±—ã—Ç–∏–µ):"
            f"\n{context_str}"
        )

    prompt = "\n".join(prompt_parts)

    response_text = _send_prompt_to_gemini(prompt)
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –æ—Ç–≤–µ—Ç JSON-–æ—à–∏–±–∫–æ–π
    # –¢–∞–∫ –∫–∞–∫ _send_prompt_to_gemini –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å JSON, –∞ –Ω–∞–º –Ω—É–∂–µ–Ω –ø—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç,
    # –º—ã –¥–µ–ª–∞–µ–º –ø—Ä–æ—Å—Ç—É—é –ø—Ä–æ–≤–µ—Ä–∫—É.
    if response_text.strip().startswith('{'):
        # –≠—Ç–æ, —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ, –∞–≤–∞—Ä–∏–π–Ω—ã–π JSON. –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–ø–∞—Å–Ω–æ–π —Ç–µ–∫—Å—Ç.
        return "–¢–∞–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π —Ç—É–º–∞–Ω —Å–∫—Ä—ã–≤–∞–µ—Ç —ç—Ç–æ –º–µ—Å—Ç–æ –æ—Ç –≤–∞—à–∏—Ö –≥–ª–∞–∑..."
    else:
        return response_text
        
def generate_action_result(context: dict, memories: List[str], player_action: str) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç JSON-–æ—Ç–≤–µ—Ç –¥–ª—è —Ä–µ–∂–∏–º–∞ –ò–°–°–õ–ï–î–û–í–ê–ù–ò–Ø."""
    prompt = f"""
    –¢—ã ‚Äî –ú–∞—Å—Ç–µ—Ä –ü–æ–¥–∑–µ–º–µ–ª–∏–π –≤ —Ä–µ–∂–∏–º–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –æ—Ç—Ä–µ–∞–≥–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ –¥–µ–π—Å—Ç–≤–∏–µ –∏–≥—Ä–æ–∫–∞.
    –¢–≤–æ–π –æ—Ç–≤–µ—Ç –î–û–õ–ñ–ï–ù –ë–´–¢–¨ —Å—Ç—Ä–æ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON —Å –∫–ª—é—á–∞–º–∏ "narrative" –∏ "state_changes".

    # V-- –≠–¢–ê –ò–ù–°–¢–†–£–ö–¶–ò–Ø –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–ê --V
    –ö–õ–Æ–ß–ï–í–û–ï –ü–†–ê–í–ò–õ–û: –ï—Å–ª–∏ –¥–µ–π—Å—Ç–≤–∏–µ –∏–≥—Ä–æ–∫–∞ —è–≤–ª—è–µ—Ç—Å—è —è–≤–Ω–æ–π –∞—Ç–∞–∫–æ–π, –∞–≥—Ä–µ—Å—Å–∏–µ–π –∏–ª–∏ –ø—Ä–æ–≤–æ–∫–∞—Ü–∏–µ–π, –∫–æ—Ç–æ—Ä–∞—è –ù–ï–ò–ó–ë–ï–ñ–ù–û –≤–µ–¥–µ—Ç –∫ –Ω–∞—á–∞–ª—É –±–æ—è, —Ç—ã –û–ë–Ø–ó–ê–ù –¥–æ–±–∞–≤–∏—Ç—å –≤ "state_changes" –∫–ª—é—á "new_game_state" —Å–æ –∑–Ω–∞—á–µ–Ω–∏–µ–º "COMBAT". –í –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Å–ª—É—á–∞—è—Ö —ç—Ç–æ—Ç –∫–ª—é—á –¥–æ–±–∞–≤–ª—è—Ç—å –Ω–µ –Ω—É–∂–Ω–æ.

    –ü—Ä–∏–º–µ—Ä –Ω–∞—á–∞–ª–∞ –±–æ—è:
    - –ò–≥—Ä–æ–∫: "–Ø –∞—Ç–∞–∫—É—é —Å–ª–∏–∑—å –º–µ—á–æ–º"
    - –¢–≤–æ–π JSON: {{
        "{NARRATIVE}": "–í—ã –±—Ä–æ—Å–∞–µ—Ç–µ—Å—å –Ω–∞ —Å–ª–∏–∑—å, –∫–æ—Ç–æ—Ä–∞—è –≤—Ä–∞–∂–¥–µ–±–Ω–æ —Ä–∞–∑–¥—É–≤–∞–µ—Ç—Å—è –≤ –æ—Ç–≤–µ—Ç. –ë–æ–π –Ω–∞—á–∞–ª—Å—è!",
        "{STATE_CHANGES}": {{
            "{NEW_GAME_STATE}": "COMBAT",
            "{NEW_EVENT}": "–ò–≥—Ä–æ–∫ —Å–ø—Ä–æ–≤–æ—Ü–∏—Ä–æ–≤–∞–ª –±–æ–π —Å–æ —Å–ª–∏–∑—å—é"
        }}
    }}
    # ------------------------------------
    
    –ö–û–ù–¢–ï–ö–°–¢ –ò–ó –ò–°–¢–û–†–ò–ò –ú–ò–†–ê:
    {json.dumps(memories, ensure_ascii=False, indent=2) if memories else "–ù–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏–π."}

    –¢–ï–ö–£–©–ê–Ø –°–ò–¢–£–ê–¶–ò–Ø:
    {json.dumps(context, ensure_ascii=False, indent=2)}

    –î–ï–ô–°–¢–í–ò–ï –ò–ì–†–û–ö–ê:
    > {player_action}

    –¢–í–û–ô JSON –û–¢–í–ï–¢:
    """
    return _send_prompt_to_gemini(prompt)


def generate_combat_action_result(combat_log: List[str], lore: List[str], player_action: str) -> str:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –±–æ–µ–≤–æ–≥–æ —Ö–æ–¥–∞, –∏—Å–ø–æ–ª—å–∑—É—è –ª–æ–≥ –±–æ—è.
    """
    model = genai.GenerativeModel(MODEL_NAME)
    
    log_str = "\n".join(combat_log)
    lore_str = "\n".join(lore) if lore else "–ù–µ—Ç –æ—Å–æ–±—ã—Ö –¥–∞–Ω–Ω—ã—Ö."

    prompt = f"""
    –¢—ã ‚Äî –ú–∞—Å—Ç–µ—Ä –ü–æ–¥–∑–µ–º–µ–ª–∏–π, –≤–µ–¥—É—â–∏–π –Ω–∞–ø—Ä—è–∂–µ–Ω–Ω—É—é –±–æ–µ–≤—É—é —Å—Ü–µ–Ω—É –≤ —Ç–µ–∫—Å—Ç–æ–≤–æ–π RPG.
    –¢–≤–æ–π –æ—Ç–≤–µ—Ç –î–û–õ–ñ–ï–ù –ë–´–¢–¨ —Å—Ç—Ä–æ–≥–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON —Å –∫–ª—é—á–∞–º–∏ "narrative" –∏ "state_changes".

    –ö–õ–Æ–ß–ï–í–û–ï –ü–†–ê–í–ò–õ–û: –ï—Å–ª–∏ –±–æ–π –æ–∫–æ–Ω—á–∏–ª—Å—è –¥–µ–ª–∞–µ–º "state_changes" –∫–ª—é—á "new_game_state" —Å–æ –∑–Ω–∞—á–µ–Ω–∏–µ–º "EXPLORATION".

    –ü–†–ò–ú–ï–† –û–¢–í–ï–¢–ê –î–õ–Ø –ë–û–ï–í–û–ì–û –•–û–î–ê:
    {{
      "{NARRATIVE}": "–í—ã —É–≤–æ—Ä–∞—á–∏–≤–∞–µ—Ç–µ—Å—å –æ—Ç –∑–∞–º–∞—Ö–∞ –≥–æ–±–ª–∏–Ω–∞ –∏ –Ω–∞–Ω–æ—Å–∏—Ç–µ –æ—Ç–≤–µ—Ç–Ω—ã–π —É–¥–∞—Ä –º–µ—á–æ–º –µ–º—É –≤ –±–æ–∫. –í—Ä–∞–≥ –æ—Ç—à–∞—Ç—ã–≤–∞–µ—Ç—Å—è, –Ω–æ –µ–≥–æ —Å–æ—é–∑–Ω–∏–∫ –±—å–µ—Ç –≤–∞—Å –¥—É–±–∏–Ω–∫–æ–π –ø–æ —Å–ø–∏–Ω–µ.",
      "{STATE_CHANGES}": {{
        "{DAMAGE_PLAYER}": 3,
        "{NEW_EVENT}": "–ò–≥—Ä–æ–∫ —Ä–∞–Ω–∏–ª –≥–æ–±–ª–∏–Ω–∞, –Ω–æ –ø–æ–ª—É—á–∏–ª –æ—Ç–≤–µ—Ç–Ω—ã–π —É–¥–∞—Ä"
      }}
    }}

    –û–ø–∏—Ä–∞–π—Å—è –Ω–∞ –ü–û–õ–ù–´–ô –ª–æ–≥ –±–æ—è, —á—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø—Ä–µ–µ–º—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å. –û–ø–∏—à–∏ –Ω–µ —Ç–æ–ª—å–∫–æ –¥–µ–π—Å—Ç–≤–∏–µ –∏–≥—Ä–æ–∫–∞, –Ω–æ –∏ –æ—Ç–≤–µ—Ç–Ω—ã–π —Ö–æ–¥ –ø—Ä–æ—Ç–∏–≤–Ω–∏–∫–∞. –ë–æ–π –¥–æ–ª–∂–µ–Ω –æ—â—É—â–∞—Ç—å—Å—è –¥–∏–Ω–∞–º–∏—á–Ω—ã–º.

    –ü–û–õ–ï–ó–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø –ò–ó –ò–°–¢–û–†–ò–ò –ú–ò–†–ê (—É—è–∑–≤–∏–º–æ—Å—Ç–∏, —Ç–∞–∫—Ç–∏–∫–∞):
    {lore_str}

    –ü–û–õ–ù–´–ô –õ–û–ì –¢–ï–ö–£–©–ï–ì–û –ë–û–Ø:
    ---
    {log_str}
    ---

    –î–ï–ô–°–¢–í–ò–ï –ò–ì–†–û–ö–ê –í –≠–¢–û–ú –•–û–î–ï:
    > {player_action}

    –¢–í–û–ô JSON –û–¢–í–ï–¢ (–æ–ø–∏—à–∏ —è—Ä–∫–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏ –æ—Ç–≤–µ—Ç–Ω—ã–π —Ö–æ–¥ –≤—Ä–∞–≥–∞):
    """
    return _send_prompt_to_gemini(prompt)

def _send_prompt_to_gemini(prompt: str) -> str:
    """
    –ï–¥–∏–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –ª—é–±–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ –≤ Gemini.
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–∞–º –≤—ã–∑–æ–≤ API, –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏ –±–∞–∑–æ–≤—ã–µ –æ—à–∏–±–∫–∏.
    """
    raw_response = "" # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –¥–ª—è –ª–æ–≥–≥–µ—Ä–∞
    try:
        # 1. –í—ã–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª—å.
        model = genai.GenerativeModel(MODEL_NAME)
        
        # 2. –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å
        print("...–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ Gemini...")
        response = model.generate_content(prompt)
        raw_response = response.text.strip()
        
        return raw_response

    except Exception as e:
        print(f"üî¥ –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê API Gemini: {e}")
        raw_response = """
        {
          "{NARRATIVE}": "–í –º–∏—Ä–æ–∑–¥–∞–Ω–∏–∏ –ø—Ä–æ–∏–∑–æ—à–µ–ª —Å–±–æ–π...",
          "{STATE_CHANGES}": {}
        }
        """
        return raw_response
    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ    
    finally:
        if prompt and raw_response:
             log_llm_interaction(prompt, raw_response)